#!/usr/bin/env python
"""LLM ê¸°ë°˜ ìŠ¤í‚¤ë§ˆ í•„í„°ë§/ì„ íƒ í…ŒìŠ¤íŠ¸.

LLMì„ í™œìš©í•˜ì—¬ í…Œì´ë¸”ì„ í•„í„°ë§í•˜ê³  ì„ íƒí•˜ëŠ” ì „ëµì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

ì „ëµ:
1. Binary Selection (RSL-SQL): ì „ì²´/ê°„ì†Œ ìŠ¤í‚¤ë§ˆ ê°ê° SQL ìƒì„± â†’ LLMì´ ë” ë‚˜ì€ ê²ƒ ì„ íƒ
2. Table Purpose Cache (CORE-T): í…Œì´ë¸” ëª©ì  ë©”íƒ€ + ì§ˆì˜ ì í•©ì„± íŒë‹¨
3. Question Enrichment (E-SQL): ì§ˆì˜ì— ì—”í‹°í‹°/ë¬¸ë§¥ ì¶”ê°€ í›„ ìŠ¤í‚¤ë§ˆ ì„ íƒ

ì‚¬ìš©ë²•:
    python scripts/schema_linking_strategies/test_llm_filtering.py --test
    python scripts/schema_linking_strategies/test_llm_filtering.py --test --use-mock
    python scripts/schema_linking_strategies/test_llm_filtering.py --query "ìˆ˜ìœ¨ ë¶„ì„"
"""

import argparse
import json
import re
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "scripts" / "schema_linking_strategies"))
sys.path.insert(0, str(PROJECT_ROOT / "src"))

from base import (
    MockSchemaDatabase,
    SchemaLinkingResult,
    EvaluationMetrics,
    TEST_CASES,
    TableInfo,
    extract_keywords,
    print_result_table,
    compute_aggregate_metrics,
)


# ============================================================================
# LLM í´ë¼ì´ì–¸íŠ¸ (Mock + ì‹¤ì œ)
# ============================================================================


class MockLLMClient:
    """Mock LLM í´ë¼ì´ì–¸íŠ¸ (í…ŒìŠ¤íŠ¸ìš©)."""

    def invoke(self, prompt: str) -> str:
        """í‚¤ì›Œë“œ ê¸°ë°˜ Mock ì‘ë‹µ ìƒì„±."""
        prompt_lower = prompt.lower()
        
        # Binary Selection ì‘ë‹µ
        if "which sql is better" in prompt_lower or "ë” ë‚˜ì€" in prompt_lower:
            if "full schema" in prompt_lower:
                return "Answer: B (Refined schema SQL is better because it's more focused)"
            return "Answer: A"
        
        # Table Filtering ì‘ë‹µ
        if "relevant tables" in prompt_lower or "ê´€ë ¨ í…Œì´ë¸”" in prompt_lower:
            relevant = []
            if "ìˆ˜ìœ¨" in prompt_lower or "yield" in prompt_lower:
                relevant.append("MES_PRD_YIELD_M10")
            if "ì„¤ë¹„" in prompt_lower or "equipment" in prompt_lower:
                relevant.append("MES_EQP_MST_M10")
            if "ë¶ˆëŸ‰" in prompt_lower or "defect" in prompt_lower:
                relevant.append("MES_DEF_HIS_M10")
            if "í™€ë“œ" in prompt_lower or "hold" in prompt_lower:
                relevant.append("MES_BIZ_LOTHOLD_INF_M10")
            if "ê³µì •" in prompt_lower or "process" in prompt_lower:
                relevant.append("MES_PROC_MST_M10")
            if "íŠ¸ë˜í‚¹" in prompt_lower or "track" in prompt_lower:
                relevant.append("MES_TRK_HIS_M10")
            
            if not relevant:
                relevant = ["MES_PRD_YIELD_M10"]
            
            return f"Relevant tables: {json.dumps(relevant)}"
        
        # Question Enrichment ì‘ë‹µ
        if "enrich" in prompt_lower or "í™•ì¥" in prompt_lower:
            return """Enriched query includes:
            - Entity: fab (M10), yield data
            - Context: production analysis
            - Related: defect rate, equipment status"""
        
        return "No specific response available for this prompt."


def get_llm_client(use_mock: bool = True):
    """LLM í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜."""
    if use_mock:
        return MockLLMClient()
    
    # ì‹¤ì œ LLM í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
    try:
        from text2sql.core.config import Settings
        from text2sql.adapters.llm.openai_client import OpenAIClient
        return OpenAIClient(Settings())
    except Exception as e:
        print(f"âš ï¸ ì‹¤ì œ LLM ì—°ê²° ì‹¤íŒ¨, Mock ì‚¬ìš©: {e}")
        return MockLLMClient()


# ============================================================================
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
# ============================================================================


PROMPTS = {
    # í…Œì´ë¸” í•„í„°ë§ í”„ë¡¬í”„íŠ¸
    "table_filter": """ì£¼ì–´ì§„ ì§ˆì˜ì™€ ê´€ë ¨ëœ í…Œì´ë¸”ì„ ì„ íƒí•˜ì„¸ìš”.

ì§ˆì˜: {query}

ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸”:
{table_list}

ìœ„ í…Œì´ë¸” ì¤‘ì—ì„œ ì§ˆì˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° í•„ìš”í•œ í…Œì´ë¸”ë§Œ ì„ íƒí•˜ì„¸ìš”.
JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ í…Œì´ë¸”ëª…ì„ ë°˜í™˜í•˜ì„¸ìš”.

Relevant tables:""",

    # Binary Selection í”„ë¡¬í”„íŠ¸
    "binary_selection": """ë‘ SQL ì¿¼ë¦¬ ì¤‘ ë” ë‚˜ì€ ê²ƒì„ ì„ íƒí•˜ì„¸ìš”.

ì§ˆì˜: {query}

SQL A (Full schema):
{sql_a}

SQL B (Refined schema):
{sql_b}

ì–´ë–¤ SQLì´ ë” ì •í™•í•˜ê³  íš¨ìœ¨ì ì¸ê°€ìš”?
"Answer: A" ë˜ëŠ” "Answer: B"ë¡œ ë‹µí•˜ì„¸ìš”.

Answer:""",

    # Question Enrichment í”„ë¡¬í”„íŠ¸
    "question_enrichment": """ë‹¤ìŒ ì§ˆì˜ë¥¼ ë¶„ì„í•˜ì—¬ ê´€ë ¨ ì—”í‹°í‹°ì™€ ë¬¸ë§¥ì„ ì¶”ì¶œí•˜ì„¸ìš”.

ì§ˆì˜: {query}

ë„ë©”ì¸: ë°˜ë„ì²´ ì œì¡° (MES ì‹œìŠ¤í…œ)

ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
1. ì–¸ê¸‰ëœ ì—”í‹°í‹° (íŒ¹, ì„¤ë¹„, ê³µì • ë“±)
2. í•„ìš”í•œ ë°ì´í„° ìœ í˜• (ìˆ˜ìœ¨, ë¶ˆëŸ‰ë¥ , ìƒì‚°ëŸ‰ ë“±)
3. ê´€ë ¨ë  ìˆ˜ ìˆëŠ” ì¶”ê°€ ë°ì´í„°

Enriched query includes:""",

    # Table Purpose í”„ë¡¬í”„íŠ¸
    "table_purpose": """í…Œì´ë¸”ì˜ ëª©ì ê³¼ ì§ˆì˜ì™€ì˜ ì í•©ì„±ì„ í‰ê°€í•˜ì„¸ìš”.

ì§ˆì˜: {query}

í…Œì´ë¸”: {table_name}
ì„¤ëª…: {table_desc}
ì»¬ëŸ¼: {columns}

ì´ í…Œì´ë¸”ì´ ì§ˆì˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° í•„ìš”í•œê°€ìš”?
1-10 ì ìˆ˜ì™€ ì´ìœ ë¥¼ ì œê³µí•˜ì„¸ìš”.

Score:""",
}


# ============================================================================
# Binary Selection (RSL-SQL ìŠ¤íƒ€ì¼)
# ============================================================================


class BinarySelectionLinker:
    """Binary Selection ê¸°ë°˜ ìŠ¤í‚¤ë§ˆ ë§í‚¹.
    
    ì „ì²´ ìŠ¤í‚¤ë§ˆì™€ ê°„ì†Œí™”ëœ ìŠ¤í‚¤ë§ˆë¡œ ê°ê° SQLì„ ìƒì„±í•˜ê³ ,
    LLMì´ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
    """

    def __init__(self, schema_db: MockSchemaDatabase, llm_client):
        self.schema_db = schema_db
        self.llm = llm_client

    def link(self, query: str, top_k: int = 5) -> SchemaLinkingResult:
        """Binary Selection ìˆ˜í–‰."""
        # 1. ì „ì²´ ìŠ¤í‚¤ë§ˆë¡œ SQL ìƒì„± (Mock)
        full_schema_sql = self._generate_sql_with_full_schema(query)
        
        # 2. ê°„ì†Œí™”ëœ ìŠ¤í‚¤ë§ˆë¡œ SQL ìƒì„±
        refined_tables = self._get_refined_tables(query)
        refined_schema_sql = self._generate_sql_with_refined_schema(query, refined_tables)
        
        # 3. LLMì—ê²Œ ì„ íƒ ìš”ì²­
        selected = self._ask_llm_to_select(query, full_schema_sql, refined_schema_sql)
        
        # 4. ì„ íƒëœ SQLì—ì„œ í…Œì´ë¸” ì¶”ì¶œ
        if selected == "B":
            final_tables = refined_tables
        else:
            final_tables = self._extract_tables(full_schema_sql)
        
        # ì ìˆ˜ ê³„ì‚° (ì„ íƒëœ í…Œì´ë¸”ì— ë†’ì€ ì ìˆ˜)
        scores = {}
        for i, table_name in enumerate(self.schema_db.get_table_names()):
            if table_name in final_tables:
                scores[table_name] = 1.0 - (final_tables.index(table_name) * 0.1)
            else:
                scores[table_name] = 0.1
        
        return SchemaLinkingResult(
            query=query,
            selected_tables=final_tables[:top_k],
            scores=scores,
        )

    def _generate_sql_with_full_schema(self, query: str) -> str:
        """ì „ì²´ ìŠ¤í‚¤ë§ˆë¡œ SQL ìƒì„± (Mock)."""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ SQL ìƒì„±
        keywords = extract_keywords(query)
        tables = []
        
        for table in self.schema_db.get_all_tables():
            if any(kw.lower() in table.name.lower() or 
                   kw.lower() in table.description.lower() 
                   for kw in keywords):
                tables.append(table.name)
        
        if not tables:
            tables = [self.schema_db.get_all_tables()[0].name]
        
        return f"SELECT * FROM {tables[0]} -- full schema"

    def _get_refined_tables(self, query: str) -> list[str]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ í…Œì´ë¸” ì •ì œ."""
        keywords = extract_keywords(query)
        scored_tables = []
        
        for table in self.schema_db.get_all_tables():
            score = 0
            for kw in keywords:
                if kw.lower() in table.name.lower():
                    score += 2
                if kw.lower() in table.description.lower():
                    score += 1
            if score > 0:
                scored_tables.append((table.name, score))
        
        scored_tables.sort(key=lambda x: -x[1])
        return [t[0] for t in scored_tables[:5]]

    def _generate_sql_with_refined_schema(self, query: str, tables: list[str]) -> str:
        """ì •ì œëœ ìŠ¤í‚¤ë§ˆë¡œ SQL ìƒì„± (Mock)."""
        if not tables:
            return "SELECT * FROM UNKNOWN -- refined"
        return f"SELECT * FROM {tables[0]} -- refined schema"

    def _ask_llm_to_select(self, query: str, sql_a: str, sql_b: str) -> str:
        """LLMì—ê²Œ ë” ë‚˜ì€ SQL ì„ íƒ ìš”ì²­."""
        prompt = PROMPTS["binary_selection"].format(
            query=query, sql_a=sql_a, sql_b=sql_b
        )
        response = self.llm.invoke(prompt)
        
        if "B" in response.upper():
            return "B"
        return "A"

    def _extract_tables(self, sql: str) -> list[str]:
        """SQLì—ì„œ í…Œì´ë¸”ëª… ì¶”ì¶œ."""
        matches = re.findall(r"FROM\s+([A-Za-z0-9_]+)", sql, re.IGNORECASE)
        matches += re.findall(r"JOIN\s+([A-Za-z0-9_]+)", sql, re.IGNORECASE)
        return list(dict.fromkeys(matches))  # ìˆœì„œ ìœ ì§€í•˜ë©° ì¤‘ë³µ ì œê±°


# ============================================================================
# Table Purpose Cache (CORE-T ìŠ¤íƒ€ì¼)
# ============================================================================


class TablePurposeCacheLinker:
    """Table Purpose Cache ê¸°ë°˜ ìŠ¤í‚¤ë§ˆ ë§í‚¹.
    
    í…Œì´ë¸”ì˜ ëª©ì  ë©”íƒ€ë°ì´í„°ì™€ ì§ˆì˜ ì í•©ì„±ì„ íŒë‹¨í•©ë‹ˆë‹¤.
    """

    def __init__(self, schema_db: MockSchemaDatabase, llm_client):
        self.schema_db = schema_db
        self.llm = llm_client
        self.purpose_cache: dict[str, dict] = {}
        self._build_purpose_cache()

    def _build_purpose_cache(self) -> None:
        """í…Œì´ë¸” ëª©ì  ìºì‹œ êµ¬ì¶•."""
        for table in self.schema_db.get_all_tables():
            self.purpose_cache[table.name] = {
                "purpose": table.purpose or table.description,
                "keywords": self._extract_purpose_keywords(table),
                "data_type": self._infer_data_type(table),
            }

    def _extract_purpose_keywords(self, table: TableInfo) -> list[str]:
        """í…Œì´ë¸” ëª©ì ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ."""
        text = f"{table.name} {table.description} {table.purpose}"
        return extract_keywords(text)

    def _infer_data_type(self, table: TableInfo) -> str:
        """í…Œì´ë¸”ì˜ ë°ì´í„° ìœ í˜• ì¶”ë¡ ."""
        name = table.name.upper()
        if "MST" in name:
            return "master"
        if "HIS" in name:
            return "history"
        if "INF" in name:
            return "information"
        if "TRK" in name:
            return "tracking"
        return "data"

    def link(self, query: str, top_k: int = 5) -> SchemaLinkingResult:
        """Table Purpose ê¸°ë°˜ ë§í‚¹ ìˆ˜í–‰."""
        query_keywords = set(extract_keywords(query))
        
        scores = {}
        for table_name, cache in self.purpose_cache.items():
            # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
            purpose_keywords = set(cache["keywords"])
            keyword_overlap = len(query_keywords & purpose_keywords)
            keyword_score = keyword_overlap / max(len(query_keywords), 1)
            
            # ë°ì´í„° ìœ í˜• ë³´ì •
            data_type_boost = 0.0
            if cache["data_type"] == "history":
                data_type_boost = 0.1  # ì´ë ¥ í…Œì´ë¸” ì„ í˜¸
            
            scores[table_name] = keyword_score + data_type_boost
        
        # ìƒìœ„ kê°œ ì„ íƒ
        sorted_tables = sorted(scores.items(), key=lambda x: -x[1])
        selected = [t[0] for t in sorted_tables[:top_k]]
        
        return SchemaLinkingResult(
            query=query,
            selected_tables=selected,
            scores=scores,
        )


# ============================================================================
# Question Enrichment (E-SQL ìŠ¤íƒ€ì¼)
# ============================================================================


class QuestionEnrichmentLinker:
    """Question Enrichment ê¸°ë°˜ ìŠ¤í‚¤ë§ˆ ë§í‚¹.
    
    ì§ˆì˜ì— ì—”í‹°í‹°ì™€ ë¬¸ë§¥ì„ ì¶”ê°€í•˜ì—¬ ìŠ¤í‚¤ë§ˆ ì„ íƒ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
    """

    def __init__(self, schema_db: MockSchemaDatabase, llm_client):
        self.schema_db = schema_db
        self.llm = llm_client

    def link(self, query: str, top_k: int = 5) -> SchemaLinkingResult:
        """Question Enrichment ìˆ˜í–‰."""
        # 1. ì§ˆì˜ ê°•í™”
        enriched_info = self._enrich_question(query)
        
        # 2. ê°•í™”ëœ ì •ë³´ë¡œ í…Œì´ë¸” ë§¤ì¹­
        scores = self._match_with_enriched_query(query, enriched_info)
        
        # ìƒìœ„ kê°œ ì„ íƒ
        sorted_tables = sorted(scores.items(), key=lambda x: -x[1])
        selected = [t[0] for t in sorted_tables[:top_k]]
        
        return SchemaLinkingResult(
            query=query,
            selected_tables=selected,
            scores=scores,
        )

    def _enrich_question(self, query: str) -> dict:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì§ˆì˜ ê°•í™”."""
        prompt = PROMPTS["question_enrichment"].format(query=query)
        response = self.llm.invoke(prompt)
        
        # ì‘ë‹µ íŒŒì‹± (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ)
        return {
            "entities": self._extract_entities(response),
            "data_types": self._extract_data_types(response),
            "original_keywords": extract_keywords(query),
        }

    def _extract_entities(self, text: str) -> list[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ."""
        entities = []
        # íŒ¹ ID ì¶”ì¶œ
        fab_match = re.findall(r"(M10|M11|M14|M15|M16)", text, re.IGNORECASE)
        entities.extend(fab_match)
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = extract_keywords(text)
        entities.extend(keywords)
        
        return list(set(entities))

    def _extract_data_types(self, text: str) -> list[str]:
        """í•„ìš”í•œ ë°ì´í„° ìœ í˜• ì¶”ì¶œ."""
        data_types = []
        type_keywords = {
            "yield": "ìˆ˜ìœ¨",
            "defect": "ë¶ˆëŸ‰",
            "equipment": "ì„¤ë¹„",
            "production": "ìƒì‚°",
            "tracking": "íŠ¸ë˜í‚¹",
        }
        
        for eng, kor in type_keywords.items():
            if eng in text.lower() or kor in text:
                data_types.append(eng)
        
        return data_types

    def _match_with_enriched_query(self, query: str, enriched: dict) -> dict[str, float]:
        """ê°•í™”ëœ ì§ˆì˜ë¡œ í…Œì´ë¸” ë§¤ì¹­."""
        all_keywords = set(enriched["original_keywords"])
        all_keywords.update(enriched["entities"])
        
        # ë°ì´í„° ìœ í˜• ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ê°€
        type_to_keywords = {
            "yield": ["yield", "ìˆ˜ìœ¨", "PRD_YIELD"],
            "defect": ["defect", "ë¶ˆëŸ‰", "DEF"],
            "equipment": ["equipment", "ì„¤ë¹„", "EQP"],
            "production": ["ìƒì‚°", "PRD"],
            "tracking": ["tracking", "íŠ¸ë˜í‚¹", "TRK"],
        }
        
        for data_type in enriched.get("data_types", []):
            if data_type in type_to_keywords:
                all_keywords.update(type_to_keywords[data_type])
        
        scores = {}
        for table in self.schema_db.get_all_tables():
            score = 0.0
            table_text = f"{table.name} {table.description} {table.purpose}"
            
            for kw in all_keywords:
                if kw.lower() in table_text.lower():
                    score += 0.2
            
            scores[table.name] = min(score, 1.0)
        
        return scores


# ============================================================================
# í†µí•© LLM ìŠ¤í‚¤ë§ˆ ë§ì»¤
# ============================================================================


class LLMSchemaLinker:
    """LLM ê¸°ë°˜ í†µí•© ìŠ¤í‚¤ë§ˆ ë§ì»¤."""

    def __init__(
        self,
        schema_db: MockSchemaDatabase,
        use_mock_llm: bool = True,
        strategy: str = "table_purpose",
    ):
        self.schema_db = schema_db
        self.llm = get_llm_client(use_mock_llm)
        self.strategy = strategy
        
        # ì „ëµë³„ ë§ì»¤ ì´ˆê¸°í™”
        self.linkers = {
            "binary_selection": BinarySelectionLinker(schema_db, self.llm),
            "table_purpose": TablePurposeCacheLinker(schema_db, self.llm),
            "question_enrichment": QuestionEnrichmentLinker(schema_db, self.llm),
        }

    def link(self, query: str, top_k: int = 5) -> SchemaLinkingResult:
        """ì„ íƒëœ ì „ëµìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ë§í‚¹ ìˆ˜í–‰."""
        linker = self.linkers.get(self.strategy, self.linkers["table_purpose"])
        return linker.link(query, top_k)


# ============================================================================
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
# ============================================================================


def run_tests(use_mock: bool = True) -> None:
    """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰."""
    print("=" * 80)
    print("LLM ê¸°ë°˜ ìŠ¤í‚¤ë§ˆ í•„í„°ë§ í…ŒìŠ¤íŠ¸")
    print(f"LLM: {'Mock' if use_mock else 'Real'}")
    print("=" * 80)
    
    schema_db = MockSchemaDatabase()
    
    strategies = ["binary_selection", "table_purpose", "question_enrichment"]
    
    for strategy in strategies:
        print(f"\n\n{'='*40}")
        print(f"ì „ëµ: {strategy}")
        print(f"{'='*40}")
        
        linker = LLMSchemaLinker(
            schema_db=schema_db,
            use_mock_llm=use_mock,
            strategy=strategy,
        )
        
        results = []
        for test_case in TEST_CASES:
            result = linker.link(test_case["query"], top_k=5)
            result.ground_truth = test_case["ground_truth"]
            results.append(result)
        
        print_result_table(results)
        
        # ì§‘ê³„ ì§€í‘œ
        aggregate = compute_aggregate_metrics(results)
        print("\nğŸ“Š ì§‘ê³„ ì§€í‘œ:")
        for metric, value in aggregate.items():
            print(f"  {metric}: {value:.4f}")


def run_single_query(query: str, strategy: str = "table_purpose", use_mock: bool = True) -> None:
    """ë‹¨ì¼ ì§ˆì˜ í…ŒìŠ¤íŠ¸."""
    print(f"\nì§ˆì˜: {query}")
    print(f"ì „ëµ: {strategy}")
    print(f"LLM: {'Mock' if use_mock else 'Real'}")
    print("-" * 60)
    
    schema_db = MockSchemaDatabase()
    linker = LLMSchemaLinker(
        schema_db=schema_db,
        use_mock_llm=use_mock,
        strategy=strategy,
    )
    
    result = linker.link(query, top_k=5)
    
    print("\nì„ ì •ëœ í…Œì´ë¸”:")
    for i, table in enumerate(result.selected_tables, 1):
        score = result.scores.get(table, 0.0)
        print(f"  {i}. {table} (score: {score:.4f})")


def main():
    """ë©”ì¸ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(
        description="LLM ê¸°ë°˜ ìŠ¤í‚¤ë§ˆ í•„í„°ë§ í…ŒìŠ¤íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument(
        "--test",
        action="store_true",
        help="ì „ì²´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰",
    )
    parser.add_argument(
        "--query",
        type=str,
        default=None,
        help="í…ŒìŠ¤íŠ¸í•  ìì—°ì–´ ì§ˆì˜",
    )
    parser.add_argument(
        "--strategy",
        type=str,
        choices=["binary_selection", "table_purpose", "question_enrichment"],
        default="table_purpose",
        help="ì‚¬ìš©í•  ì „ëµ (ê¸°ë³¸ê°’: table_purpose)",
    )
    parser.add_argument(
        "--use-mock",
        action="store_true",
        default=True,
        help="Mock LLM ì‚¬ìš© (ê¸°ë³¸ê°’: True)",
    )
    parser.add_argument(
        "--use-real-llm",
        action="store_true",
        help="ì‹¤ì œ LLM ì‚¬ìš©",
    )
    
    args = parser.parse_args()
    use_mock = not args.use_real_llm
    
    if args.test:
        run_tests(use_mock)
    elif args.query:
        run_single_query(args.query, args.strategy, use_mock)
    else:
        print("LLM ê¸°ë°˜ ìŠ¤í‚¤ë§ˆ í•„í„°ë§ ë°ëª¨")
        print("-" * 40)
        run_single_query("M10 íŒ¹ì˜ ìˆ˜ìœ¨ ë°ì´í„°ë¥¼ ë³´ì—¬ì¤˜", "table_purpose", use_mock)


if __name__ == "__main__":
    main()
