#!/usr/bin/env python
"""ê°œë³„ ì»´í¬ë„ŒíŠ¸ ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸.

íŒŒì´í”„ë¼ì¸ì˜ ê° ì»´í¬ë„ŒíŠ¸ë¥¼ ê°œë³„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python scripts/demo_components.py normalizer    # SQL ì •ê·œí™” ë°ëª¨
    python scripts/demo_components.py filter        # ë¡œê·¸ í•„í„° ë°ëª¨
    python scripts/demo_components.py glossary      # ìš©ì–´ ì‚¬ì „ ë°ëª¨
"""

import argparse
import json
import sys
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "src"))

from text2sql.core.models import RawSQLLog, GlossaryTerm
from text2sql.offline.ingestor.log_filter import LogFilter
from text2sql.offline.processor.sql_normalizer import SQLNormalizer
from text2sql.offline.schema.glossary_builder import GlossaryBuilder


def demo_normalizer():
    """SQL ì •ê·œí™”ê¸° ë°ëª¨."""
    print("\n" + "=" * 60)
    print("ğŸ”§ SQL ì •ê·œí™”ê¸° ë°ëª¨")
    print("=" * 60)

    normalizer = SQLNormalizer()

    sample_sqls = [
        "SELECT * FROM customers WHERE customer_id = 12345",
        "SELECT name, email FROM users WHERE created_at > '2025-01-01'",
        "SELECT * FROM products WHERE price > 100.50 AND category = 'ELECTRONICS'",
        "SELECT o.*, c.name FROM orders o JOIN customers c ON o.customer_id = c.id WHERE o.id IN (1, 2, 3, 4, 5)",
    ]

    for sql in sample_sqls:
        print(f"\nğŸ“ ì›ë³¸ SQL:")
        print(f"   {sql}")

        normalized = normalizer.normalize_literals(sql)
        tables = normalizer.extract_tables(sql)
        columns = normalizer.extract_columns(sql)

        print(f"\nğŸ”„ ì •ê·œí™”ëœ SQL:")
        print(f"   {normalized}")
        print(f"\nğŸ“Š ì¶”ì¶œëœ ë©”íƒ€ë°ì´í„°:")
        print(f"   - í…Œì´ë¸”: {tables}")
        print(f"   - ì»¬ëŸ¼: {columns}")
        print("-" * 60)


def demo_filter():
    """ë¡œê·¸ í•„í„° ë°ëª¨."""
    print("\n" + "=" * 60)
    print("ğŸ” ë¡œê·¸ í•„í„° ë°ëª¨")
    print("=" * 60)

    # ìƒ˜í”Œ ë¡œê·¸ ë¡œë“œ
    sample_path = PROJECT_ROOT / "data" / "samples" / "sql_logs.json"
    with open(sample_path, encoding="utf-8") as f:
        data = json.load(f)

    logs = []
    for item in data:
        log = RawSQLLog(
            sql_id=item["sql_id"],
            sql_text=item["sql_text"],
            exec_count=item["exec_count"],
            error_count=item["error_count"],
            collected_at=datetime.fromisoformat(item["collected_at"]),
            schema_name=item.get("schema_name"),
        )
        logs.append(log)

    print(f"\nğŸ“‚ ë¡œë“œëœ ì „ì²´ ë¡œê·¸: {len(logs)}ê°œ")

    # í•„í„°ë§
    log_filter = LogFilter()
    filtered = log_filter.filter(logs)

    print(f"âœ… í•„í„°ë§ í›„ ë¡œê·¸: {len(filtered)}ê°œ")
    print(f"âŒ ì œì™¸ëœ ë¡œê·¸: {len(logs) - len(filtered)}ê°œ")

    # ì œì™¸ëœ ë¡œê·¸ ë¶„ì„
    excluded = [log for log in logs if log not in filtered]
    print("\nğŸ“‹ ì œì™¸ëœ ë¡œê·¸ ìƒì„¸:")
    for log in excluded:
        reason = []
        if log.error_count > 0:
            reason.append("ì—ëŸ¬ ìˆìŒ")
        if log.sql_text.strip().upper().startswith(("INSERT", "UPDATE", "DELETE")):
            reason.append("DML")
        if log.sql_text.strip().upper().startswith(("CREATE", "ALTER", "DROP")):
            reason.append("DDL")
        if "DBA_" in log.sql_text or "SYS." in log.sql_text:
            reason.append("ì‹œìŠ¤í…œ ì¿¼ë¦¬")
        print(f"   - {log.sql_id}: {', '.join(reason)}")

    # ìƒìœ„ 5ê°œ ì¶œë ¥
    print("\nğŸ† ìƒìœ„ 5ê°œ í•„í„°ë§ëœ ë¡œê·¸:")
    for log in filtered[:5]:
        print(f"   - {log.sql_id} (exec_count: {log.exec_count})")
        print(f"     {log.sql_text[:80]}...")


def demo_glossary():
    """ìš©ì–´ ì‚¬ì „ ë°ëª¨."""
    print("\n" + "=" * 60)
    print("ğŸ“– ìš©ì–´ ì‚¬ì „ ë°ëª¨")
    print("=" * 60)

    # CSV ë¡œë“œ
    glossary_path = PROJECT_ROOT / "data" / "samples" / "glossary.csv"
    builder = GlossaryBuilder()

    print(f"\nğŸ“‚ ìš©ì–´ ì‚¬ì „ ë¡œë“œ: {glossary_path}")
    raw_terms = builder.parse_csv(glossary_path)
    print(f"   - ë¡œë“œëœ ìš©ì–´ ìˆ˜: {len(raw_terms)}ê°œ")

    # GlossaryTerm ê°ì²´ ìƒì„±
    terms = [builder.create_term(t) for t in raw_terms]

    # ì¹´í…Œê³ ë¦¬ë³„ ê·¸ë£¹í™”
    categories: dict[str, list[GlossaryTerm]] = {}
    for term in terms:
        cat = term.category or "ê¸°íƒ€"
        if cat not in categories:
            categories[cat] = []
        categories[cat].append(term)

    print("\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ìš©ì–´:")
    for cat, cat_terms in sorted(categories.items()):
        print(f"\n   [{cat}] ({len(cat_terms)}ê°œ)")
        for term in cat_terms[:3]:  # ê° ì¹´í…Œê³ ë¦¬ë³„ ìµœëŒ€ 3ê°œë§Œ ì¶œë ¥
            print(f"     - {term.term} ({term.korean_name})")
        if len(cat_terms) > 3:
            print(f"     ... ì™¸ {len(cat_terms) - 3}ê°œ")

    # ê²€ìƒ‰ ì˜ˆì‹œ
    print("\nğŸ” ê²€ìƒ‰ ì˜ˆì‹œ:")
    search_terms = ["customer", "order", "salary"]
    for search in search_terms:
        matches = [t for t in terms if search in t.term.lower()]
        if matches:
            print(f"   '{search}' ê²€ìƒ‰ ê²°ê³¼:")
            for match in matches[:3]:
                print(f"     - {match.term}: {match.korean_name} - {match.description[:30]}...")


def main():
    """ë©”ì¸ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(
        description="Text2SQL ê°œë³„ ì»´í¬ë„ŒíŠ¸ ë°ëª¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument(
        "component",
        choices=["normalizer", "filter", "glossary", "all"],
        help="ë°ëª¨í•  ì»´í¬ë„ŒíŠ¸ ì„ íƒ",
    )

    args = parser.parse_args()

    if args.component == "normalizer" or args.component == "all":
        demo_normalizer()
    if args.component == "filter" or args.component == "all":
        demo_filter()
    if args.component == "glossary" or args.component == "all":
        demo_glossary()

    print("\nâœ… ë°ëª¨ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
